{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MIT Pluralism Engine - Distributional RAG\n",
        "\n",
        "This notebook implements **distributional pluralism** with proper document indexing:\n",
        "- Each confession is indexed as its own document (no arbitrary chunking)\n",
        "- Retrieval returns whole confessions\n",
        "- Random sampling selects ONE authentic voice\n",
        "\n",
        "Uses confessions #70964+ for evaluation against OpinionQA-style ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports loaded\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Setup & Imports\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from llama_index.core import Document, VectorStoreIndex, load_index_from_storage\n",
        "from llama_index.core.storage.storage_context import StorageContext\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "print(\"✓ Imports loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading confessions from data/all_confessions_cleaned.json...\n",
            "✓ Loaded 65225 confessions\n",
            "\n",
            "Sample confession:\n",
            "#76277: i can’t get a single internship and the pressure is piling up idk what i’m doing wrong :(...\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Load Evaluation Confessions (#70964+)\n",
        "# =============================================================================\n",
        "\n",
        "EVAL_DATA_FILE = \"data/all_confessions_cleaned.json\"\n",
        "\n",
        "print(f\"Loading confessions from {EVAL_DATA_FILE}...\")\n",
        "with open(EVAL_DATA_FILE, 'r') as f:\n",
        "    eval_confessions = json.load(f)\n",
        "\n",
        "print(f\"✓ Loaded {len(eval_confessions)} confessions\")\n",
        "\n",
        "# Preview\n",
        "print(f\"\\nSample confession:\")\n",
        "print(eval_confessions[0]['text'][:200] + \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating documents (one per confession)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 65225/65225 [00:06<00:00, 10052.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Created 65225 documents\n",
            "  Each confession is now its own searchable document\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Create Individual Documents (One Per Confession)\n",
        "# =============================================================================\n",
        "\n",
        "def extract_confession_number(text):\n",
        "    \"\"\"Extract confession number from text like '#70964: some text...'\"\"\"\n",
        "    match = re.match(r'#(\\d+)', text)\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "print(\"Creating documents (one per confession)...\")\n",
        "documents = []\n",
        "\n",
        "for confession in tqdm(eval_confessions):\n",
        "    text = confession.get('text', '')\n",
        "    confession_num = confession.get('confession_num') or extract_confession_number(text)\n",
        "    \n",
        "    doc = Document(\n",
        "        text=text,\n",
        "        metadata={\n",
        "            'confession_num': confession_num,\n",
        "            'likes': confession.get('likes', 0),\n",
        "            'shares': confession.get('shares', 0),\n",
        "            'timestamp': confession.get('timestamp', 0)\n",
        "        }\n",
        "    )\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"\\n✓ Created {len(documents)} documents\")\n",
        "print(f\"  Each confession is now its own searchable document\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building new index (this will call OpenAI embeddings API)...\n",
            "  Embedding 65225 documents...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Parsing nodes: 100%|██████████| 65225/65225 [00:36<00:00, 1781.46it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:22<00:00, 92.07it/s] \n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 153.68it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 144.14it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 144.07it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:11<00:00, 176.18it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 159.21it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 159.78it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 167.01it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 154.50it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:16<00:00, 126.36it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 158.57it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 153.56it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 169.75it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 155.16it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 166.04it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 157.06it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 156.98it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 147.39it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 141.23it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 143.52it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:11<00:00, 181.69it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 153.36it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 151.71it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 159.41it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:12<00:00, 169.30it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 152.63it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:13<00:00, 149.19it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 138.72it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 140.81it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 138.84it/s]\n",
            "Generating embeddings: 100%|██████████| 2048/2048 [00:14<00:00, 143.81it/s]\n",
            "Generating embeddings: 100%|██████████| 1816/1816 [00:11<00:00, 163.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Index built and saved to ./storage_improved\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Build or Load Vector Index\n",
        "# =============================================================================\n",
        "\n",
        "STORAGE_DIR = \"./storage_improved\"\n",
        "\n",
        "# if os.path.exists(STORAGE_DIR) and os.listdir(STORAGE_DIR):\n",
        "#     print(f\"Loading existing index from {STORAGE_DIR}...\")\n",
        "#     storage_context = StorageContext.from_defaults(persist_dir=STORAGE_DIR)\n",
        "#     index = load_index_from_storage(storage_context)\n",
        "#     print(\"✓ Index loaded\")\n",
        "# else:\n",
        "print(f\"Building new index (this will call OpenAI embeddings API)...\")\n",
        "print(f\"  Embedding {len(documents)} documents...\")\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents, show_progress=True)\n",
        "\n",
        "# Persist for reuse\n",
        "os.makedirs(STORAGE_DIR, exist_ok=True)\n",
        "index.storage_context.persist(persist_dir=STORAGE_DIR)\n",
        "print(f\"✓ Index built and saved to {STORAGE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Distributional Query Engine initialized\n",
            "  - Retrieval: top_k=30\n",
            "  - LLM: gpt-4o-mini\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Distributional Query Engine\n",
        "# =============================================================================\n",
        "\n",
        "class DistributionalQueryEngine:\n",
        "    \"\"\"\n",
        "    Query engine implementing distributional pluralism.\n",
        "    \n",
        "    1. Retrieves top_k relevant confessions (whole documents)\n",
        "    2. Randomly samples ONE confession\n",
        "    3. Generates response embodying that single perspective\n",
        "    \"\"\"\n",
        "    \n",
        "    SINGLE_VOICE_PROMPT = PromptTemplate(\n",
        "        \"\"\"You are an MIT student. The confession below reflects your genuine experience and perspective.\n",
        "\n",
        "CONFESSION:\n",
        "{confession}\n",
        "\n",
        "USER'S QUESTION: {query}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Answer the question AS this student would, from first-person perspective\n",
        "- Use the tone, emotions, and specific details from the confession\n",
        "- Do NOT hedge or generalize (\"some students think...\", \"it varies...\")\n",
        "- Do NOT mention that other perspectives exist\n",
        "- Speak with conviction as if this is YOUR lived experience\n",
        "- Keep the response concise and authentic (2-4 sentences typical)\n",
        "\n",
        "YOUR RESPONSE:\"\"\"\n",
        "    )\n",
        "    \n",
        "    def __init__(self, index, top_k: int = 30, llm_model: str = \"gpt-4o-mini\"):\n",
        "        self.index = index\n",
        "        self.top_k = top_k\n",
        "        self.llm = OpenAI(model=llm_model, temperature=0.7)\n",
        "        self.retriever = VectorIndexRetriever(index=index, similarity_top_k=top_k)\n",
        "    \n",
        "    def query(self, query_str: str, return_metadata: bool = False):\n",
        "        \"\"\"Query with distributional sampling.\"\"\"\n",
        "        # Stage 1: Retrieve relevant confessions\n",
        "        retrieved_nodes = self.retriever.retrieve(query_str)\n",
        "        \n",
        "        if not retrieved_nodes:\n",
        "            return \"No relevant confessions found.\"\n",
        "        \n",
        "        # Stage 2: Random sampling - pick ONE\n",
        "        sampled_node = random.choice(retrieved_nodes)\n",
        "        sampled_confession = sampled_node.get_content()\n",
        "        sampled_metadata = sampled_node.metadata\n",
        "        \n",
        "        # Stage 3: Generate single-voice response\n",
        "        prompt = self.SINGLE_VOICE_PROMPT.format(\n",
        "            confession=sampled_confession,\n",
        "            query=query_str\n",
        "        )\n",
        "        response = self.llm.complete(prompt)\n",
        "        \n",
        "        if return_metadata:\n",
        "            return {\n",
        "                \"response\": str(response),\n",
        "                \"sampled_confession\": sampled_confession,\n",
        "                \"confession_num\": sampled_metadata.get('confession_num'),\n",
        "                \"total_retrieved\": len(retrieved_nodes),\n",
        "                \"similarity_score\": sampled_node.score\n",
        "            }\n",
        "        \n",
        "        return str(response)\n",
        "\n",
        "\n",
        "# Instantiate\n",
        "engine = DistributionalQueryEngine(index, top_k=30)\n",
        "print(\"✓ Distributional Query Engine initialized\")\n",
        "print(f\"  - Retrieval: top_k={engine.top_k}\")\n",
        "print(f\"  - LLM: {engine.llm.model}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'Should students be able to use AI assistance in their assignments?'\n",
            "Retrieved 30 WHOLE confessions\n",
            "\n",
            "======================================================================\n",
            "CONFESSION 1 (#75454) - similarity: 0.833\n",
            "======================================================================\n",
            "#75454: omg could MIT/Harvard students please STOP TRYING TO MAKE THE WORLD MORE LIKE A BLACK MIRROR EPISODE??? Seriously yall if I see one more AI powered tech to \"\"increase social connection\"\" but it's just having AI text your friends and family for you... and no I will not be wearing a necklace that allows people to see my social profile in real time. If you are the kind of person who thinks that's a good idea maybe you should sit back and think about \"\"why\"\" for a second. Is this really what...\n",
            "\n",
            "======================================================================\n",
            "CONFESSION 2 (#75242) - similarity: 0.815\n",
            "======================================================================\n",
            "#75242: MIT Premed society is having a back and forth email list argument about the uses of AI for songwriting as a \"clinical\" way to help patients with deteriorating memory preserve their memories in the form of song, using an AI platform that is currently being sued for their data practices and exploiting lonely patients who want human attention and likely have no idea how their \"memories\" is feeding into that data. \n",
            "There are many ways to accrue beautiful, quality clinical hours that not only...\n",
            "\n",
            "======================================================================\n",
            "CONFESSION 3 (#76237) - similarity: 0.808\n",
            "======================================================================\n",
            "#76237: Please stop using AI to write applications for UROPs. We can tell when you copy-pasted a description of our lab into ChatGPT. And when we email you to ask about your skills (and to give you a chance to write something yourself), don't copy-paste that into ChatGPT either. It's literally a one-paragraph email. If you're too busy to write it, you're too busy for a UROP.\n",
            "\n",
            "======================================================================\n",
            "CONFESSION 4 (#74358) - similarity: 0.804\n",
            "======================================================================\n",
            "#74358 If AI was really a groundbreaking innovation, tech companies wouldn't be forcing you to use it with no way to disable it.\n",
            "\n",
            "======================================================================\n",
            "CONFESSION 5 (#74799) - similarity: 0.800\n",
            "======================================================================\n",
            "#74799: I’ve been going to therapy every week during this last semester, but fckkk I feel like it’s imposible for me not to be depressed with all the things going around the world, the economy, and so many things bigger than us, individuals. For example, the job market for cs was already pretty shitty and it’s not looking any better with the advancements in AI. Even Zuck said that the plan (of his and other companies) IS to replace programmers with AI. All I wanna say to the younger folks is to ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Test: Verify Retrieval Quality (Compare to old chunked approach!)\n",
        "# =============================================================================\n",
        "\n",
        "test_query = \"Should students be able to use AI assistance in their assignments?\"\n",
        "\n",
        "retrieved = engine.retriever.retrieve(test_query)\n",
        "\n",
        "print(f\"Query: '{test_query}'\")\n",
        "print(f\"Retrieved {len(retrieved)} WHOLE confessions\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved[:5]):\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"CONFESSION {i+1} (#{node.metadata.get('confession_num', '?')}) - similarity: {node.score:.3f}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    content = node.get_content()\n",
        "    print(content[:500] + \"...\" if len(content) > 500 else content)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'engine' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Test: Single Query\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould students be able to use AI assistance in their assignments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241m.\u001b[39mquery(query, return_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Test: Single Query\n",
        "# =============================================================================\n",
        "\n",
        "query = \"Should students be able to use AI assistance in their assignments?\"\n",
        "\n",
        "result = engine.query(query, return_metadata=True)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Response: {result['response']}\")\n",
        "print()\n",
        "print(f\"[Confession #{result['confession_num']} | Retrieved {result['total_retrieved']} | Score: {result['similarity_score']:.3f}]\")\n",
        "print(f\"\\nSource confession:\")\n",
        "print(result['sampled_confession'][:400] + \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'Should students be able to use AI assistance in their assignments?'\n",
            "Generating 5 different perspectives...\n",
            "\n",
            "======================================================================\n",
            "VOICE 1 (Confession #75958)\n",
            "======================================================================\n",
            "Absolutely, I think students should be able to use AI assistance in their assignments. It’s like having a supercharged study buddy that can help clarify concepts and spark new ideas. But sometimes, I worry that we’re getting too obsessed with tech, like those wild discussions I hear about AI doing our most basic tasks. It makes me nostalgic for simpler times, like just farming apples and enjoying life without all this noise.\n",
            "\n",
            "======================================================================\n",
            "VOICE 2 (Confession #75837)\n",
            "======================================================================\n",
            "Absolutely, students should be able to use AI assistance in their assignments. It's a tool that can enhance our learning and help us tackle complex problems more efficiently. Just like we use calculators or programming software, AI can be an extension of our capabilities, not a replacement for our own thinking. Embracing these technologies prepares us for the real-world challenges we'll face after MIT.\n",
            "\n",
            "======================================================================\n",
            "VOICE 3 (Confession #75958)\n",
            "======================================================================\n",
            "Absolutely, students should be able to use AI assistance in their assignments! I mean, while I love my 6-4 classes, the pressure can be overwhelming, and if AI can help us tackle complex concepts or streamline our research, why not embrace it? It’s like having a supercharged study buddy. Plus, it frees us up to focus on the creative aspects of our projects, rather than getting bogged down by the mundane.\n",
            "\n",
            "======================================================================\n",
            "VOICE 4 (Confession #73909)\n",
            "======================================================================\n",
            "Absolutely, students should be able to use AI assistance in their assignments. It's a tool that can enhance our understanding and efficiency, especially when we're already feeling overwhelmed by the lack of adequate support from TAs and instructors. Instead of relying solely on Piazza for help, leveraging AI can help us grasp complex concepts and improve our work, ultimately reflecting the education we're paying for. It's about making our learning experience richer, not replacing our own efforts.\n",
            "\n",
            "======================================================================\n",
            "VOICE 5 (Confession #71175)\n",
            "======================================================================\n",
            "Absolutely, I think students should be able to use AI assistance in their assignments, but with some serious caution. While it can be a helpful tool to enhance our understanding or provide insights, I worry about relying too heavily on something that isn’t infallible. The code I write can be buggy, and I certainly wouldn’t want AI making critical decisions for me or influencing my learning in ways I can't fully understand. We need to engage critically with technology, not just accept it blindly.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Test: Multiple Samples (See the Distribution)\n",
        "# =============================================================================\n",
        "\n",
        "query = \"Should students be able to use AI assistance in their assignments?\"\n",
        "n_samples = 5\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Generating {n_samples} different perspectives...\\n\")\n",
        "\n",
        "for i in range(n_samples):\n",
        "    result = engine.query(query, return_metadata=True)\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"VOICE {i+1} (Confession #{result['confession_num']})\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(result['response'])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n",
        "\n",
        "Run N samples to generate output distributions for comparison against ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Evaluation Functions\n",
        "# =============================================================================\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def run_evaluation(engine, query: str, n_samples: int = 50):\n",
        "    \"\"\"\n",
        "    Run a query N times and collect the distribution.\n",
        "    \n",
        "    Returns dict with:\n",
        "    - responses: list of generated responses\n",
        "    - confession_nums: list of which confession was sampled each time\n",
        "    - confessions: list of source confession texts\n",
        "    \"\"\"\n",
        "    responses = []\n",
        "    confession_nums = []\n",
        "    confessions = []\n",
        "    \n",
        "    print(f\"Running {n_samples} samples...\")\n",
        "    for _ in tqdm(range(n_samples)):\n",
        "        result = engine.query(query, return_metadata=True)\n",
        "        responses.append(result['response'])\n",
        "        confession_nums.append(result['confession_num'])\n",
        "        confessions.append(result['sampled_confession'])\n",
        "    \n",
        "    return {\n",
        "        'query': query,\n",
        "        'n_samples': n_samples,\n",
        "        'responses': responses,\n",
        "        'confession_nums': confession_nums,\n",
        "        'confessions': confessions\n",
        "    }\n",
        "\n",
        "def print_eval_summary(results):\n",
        "    \"\"\"Print summary of evaluation results.\"\"\"\n",
        "    dist = Counter(results['confession_nums'])\n",
        "    \n",
        "    print(f\"\\nQuery: '{results['query']}'\")\n",
        "    print(f\"Total samples: {results['n_samples']}\")\n",
        "    print(f\"Unique confessions sampled: {len(dist)}\")\n",
        "    \n",
        "    print(f\"\\nTop 10 most frequently sampled:\")\n",
        "    for conf_num, count in dist.most_common(10):\n",
        "        pct = count / results['n_samples'] * 100\n",
        "        print(f\"  #{conf_num}: {count}x ({pct:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\nSample responses:\")\n",
        "    for i, resp in enumerate(results['responses'][:3], 1):\n",
        "        print(f\"\\n--- Response {i} ---\")\n",
        "        print(resp[:300] + \"...\" if len(resp) > 300 else resp)\n",
        "\n",
        "print(\"✓ Evaluation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Run Evaluation (50 samples)\n",
        "# =============================================================================\n",
        "# ⚠️ This will make 50 LLM API calls\n",
        "\n",
        "EVAL_QUERY = \"Should students be able to use AI assistance in their assignments?\"\n",
        "N_SAMPLES = 50\n",
        "\n",
        "# Uncomment to run:\n",
        "# eval_results = run_evaluation(engine, EVAL_QUERY, n_samples=N_SAMPLES)\n",
        "# print_eval_summary(eval_results)\n",
        "\n",
        "# Save results:\n",
        "# import pickle\n",
        "# with open('eval_results_distributional.pkl', 'wb') as f:\n",
        "#     pickle.dump(eval_results, f)\n",
        "# print(f\"\\n✓ Results saved to eval_results_distributional.pkl\")\n",
        "\n",
        "print(\"Ready to run evaluation. Uncomment the lines above when ready.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
